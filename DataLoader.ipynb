{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from os import listdir, path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torchvision.transforms.functional\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TRANSFORM(object):\n",
    "    def __call__(self, image, target):\n",
    "        image = torchvision.transforms.functional.to_tensor(image)\n",
    "        image = torchvision.transforms.functional.normalize(image, mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225])\n",
    "        return image, target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "xml_paths = 'C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/pascal'\n",
    "img_dir = 'C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/images'\n",
    "LABELS = {'van': 1}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from os import listdir, path\n",
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, xml_paths, img_dir, transforms = None):\n",
    "        self.xml_paths = xml_paths\n",
    "        self.xml_files = list(sorted(listdir(path.join(xml_paths))))\n",
    "        self.img_dir = img_dir\n",
    "        self.images = list(sorted(listdir(path.join(img_dir))))\n",
    "        self.transforms = transforms\n",
    "        self.data = []\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xml_path = path.join(self.xml_paths, self.xml_files[idx])\n",
    "        img_path = path.join(self.img_dir, self.images[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        boxes , area, labels = [] , [], []\n",
    "        for obj in root.findall('object'):\n",
    "                name = obj.find('name').text\n",
    "                bndbox = obj.find('bndbox')\n",
    "                xmin = int(bndbox.find('xmin').text)\n",
    "                ymin = int(bndbox.find('ymin').text)\n",
    "                xmax = int(bndbox.find('xmax').text)\n",
    "                ymax = int(bndbox.find('ymax').text)\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                area.append((ymax - ymin) * (xmax - xmin))\n",
    "                labels.append(LABELS[name])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        image_id = torch.tensor([idx])\n",
    "        iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": image_id, \"area\": area, \"iscrowd\": iscrowd}\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "dataset = CocoDataset('C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/pascal', 'C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/images' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "xml_files = list(sorted(listdir(path.join(xml_paths))))\n",
    "images = list(sorted(listdir(path.join(img_dir))))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(10):\n",
    "    xml_path = path.join(xml_paths, xml_files[idx])\n",
    "    img_path = path.join(img_dir, images[idx])\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            data.append((img_path, (xmin, ymin, xmax, ymax), name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "[[152, 288, 798, 613]]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "xml_path = 'C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/pascal/000fe628fd1fa9d2.xml'#path.join(xml_paths, xml_files[idx])\n",
    "img_path = 'C:/Users/USER/PycharmProjects/UniWork/MinivanDetection/Dataset/van/images/000fe628fd1fa9d2.jpg'#path.join(img_dir, images[idx])\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "boxes = []\n",
    "area = []\n",
    "labels = []\n",
    "for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        area.append((ymax - ymin) * (xmax - xmin))\n",
    "        labels.append(LABELS[name])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 1]"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "l = torch.as_tensor(labels, dtype=torch.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "a = torch.as_tensor(boxes, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "b = torch.as_tensor(area, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "[27456, 20043]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
